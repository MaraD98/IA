{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "047e87c6-2f24-41fa-a85d-1af792fc59c8",
   "metadata": {},
   "source": [
    "### Pasos a seguir\n",
    "\n",
    "* Crear entorno virtual\n",
    "* Conseguir la API Key de Cohere y guardarla en un .env\n",
    "* Hacer la conexion a Cohere\n",
    "* Probar los distintos modelos que nos brinda"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e764ea5-e9f7-4525-8ed0-435131f7fe4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# requirements.txt\n",
    "#cohere\n",
    "#jupyterlab\n",
    "#python-dotenv\n",
    "#ipywidgets"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21993094-309c-4ebb-b3e4-2de1af1a8c68",
   "metadata": {},
   "source": [
    "### Algunos ejercicios"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d8f3ed3a-9967-4746-8e09-d32ba3b7186e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import ipywidgets as widgets\n",
    "from IPython.display import display, clear_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63603dbe-6aa2-4246-ad39-e0c4f9331ed6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c9116d3d-8639-4c32-9f15-10c6b2ff0da3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "419ZWKkfbVtyWRwvaRoa9nqWhB2xdfJdmJHlNRFG\n"
     ]
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "import os\n",
    "\n",
    "load_dotenv()  # Load .env file\n",
    "\n",
    "api_key = os.getenv(\"COHERE_API_KEY\")\n",
    "print(api_key)  # Verify the key is loaded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5a47983-d431-4da9-abf2-497a38c8ee8d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "1bc19866-b250-42cc-9436-51e42ba7fd24",
   "metadata": {},
   "source": [
    "### Utilizar los modelos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e37580aa-1693-4414-adb9-3960c2667bb9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hab√≠a una vez un grupo de ni√±os que viv√≠an en un peque√±o pueblo junto al mar. Cada d√≠a, despu√©s de la escuela, exploraban la playa, buscando tesoros escondidos entre las rocas y so√±ando con convertirse en valientes marineros.\n"
     ]
    }
   ],
   "source": [
    "# Establecer la conexion a cohere y hacer su primer consulta con el modelo que quieran.\n",
    "# Usen la api version v2\n",
    "\n",
    "import cohere\n",
    "co = cohere.ClientV2()\n",
    "response = co.chat(\n",
    "    model=\"command-r-plus-08-2024\",\n",
    "    messages=[{\"role\": \"user\", \"content\": \"podes contarme una historia de ni√±os en 2 renglones?\"}],\n",
    ")\n",
    "content = response.message.content[0].text\n",
    "print(content)\n",
    "\n",
    "\n",
    "\n",
    "# desafio, obtener solo el contenido en texto de la respuesta"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb6073ef-744b-4ace-a82c-fbf2962e4a4d",
   "metadata": {},
   "source": [
    "### Prompting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5040c8d2-1e5b-42c7-8c8f-03947a603f99",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Para un mismo prompt probar 3 modelos distintos para ver su variacion en performance de velocidad y calidad de respuesta.\n",
    "\n",
    "#command\n",
    "#command-light\n",
    "#command-r-plus-08-2024\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77aee753-c8bf-44ae-b74f-d2d9c99bfc93",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Paso 1, generar una historia corta 100 palabras como mucho y guardarla en una variable.\n",
    "\n",
    "# Paso 2, ir generando instrucciones para responder de cirta forma sobre la pregunta\n",
    "\n",
    "# ir agregando items\n",
    "\n",
    "# - quiero una respuesta concisa\n",
    "# - responde ademas del texto utilizando emojis que resuman la respuesta\n",
    "# - responde en tercera persona\n",
    "# - responde en el idioma que te pregunta el usuario"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d6da00b3-2ab2-46d4-a123-9e2238cebeb4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hab√≠a una vez una joven llamada Sof√≠a, quien viv√≠a en un peque√±o pueblo junto al mar. Cada d√≠a, caminaba por la playa, recogiendo conchas y so√±ando con explorar el vasto oc√©ano. Un d√≠a, encontr√≥ una botella vieja con un mensaje dentro. El mensaje hablaba de una isla lejana llena de tesoros y misterios. Sof√≠a, llena de curiosidad, decidi√≥ embarcarse en un viaje para encontrar esa isla. Naveg√≥ durante d√≠as hasta que divis√≥ una costa desconocida. Al explorar la isla, descubri√≥ ruinas antiguas y un cofre escondido con mapas que revelaban secretos del mar. Sof√≠a se convirti√≥ en una famosa exploradora, compartiendo sus aventuras con el mundo.\n"
     ]
    }
   ],
   "source": [
    "# Paso 1\n",
    "\n",
    "response = co.chat(\n",
    "    model=\"command-r-plus-08-2024\",\n",
    "    messages=[{\"role\": \"user\", \"content\": \"Contame historia una historia corta en 100 palabras\"}],\n",
    ")\n",
    "contenido = response.message.content[0].text\n",
    "print(contenido)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3323b60-88c7-41c1-bac8-2fa56cbd5b6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Paso 1\n",
    "\n",
    "response = co.chat(\n",
    "    model=\"command-r-plus-08-2024\",\n",
    "    messages=[{\"role\": \"user\", \"content\": \"Contame historia una historia corta en 100 palabras\"}],\n",
    ")\n",
    "contenido = response.message.content[0].text\n",
    "print(contenido)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ee392d97-de80-449c-8685-46516e79640d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#no me gust√≥ esa historia xD\n",
    "historia = \"\"\"Luna so√±aba con trabajar en un centro de conservaci√≥n de animales, pero su pueblo carec√≠a de oportunidades. Con esfuerzo, estudiaba biolog√≠a por las noches mientras cuidaba a su hermano menor durante el d√≠a. Un concurso de investigaci√≥n la llev√≥ a una gran ciudad, donde su proyecto sobre tortugas marinas llam√≥ la atenci√≥n de expertos. Fue contratada para liderar un programa de conservaci√≥n en una reserva natural. Luna, con una sonrisa radiante, comprob√≥ que los sue√±os se alcanzan con pasi√≥n y perseverancia.\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9e4e8a8e-cf51-4ecc-8daa-d85a32d24728",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Luna es una joven apasionada por la biolog√≠a y la conservaci√≥n animal. Demuestra una gran dedicaci√≥n al combinar sus estudios nocturnos con el cuidado de su hermano menor durante el d√≠a. Su inter√©s en la investigaci√≥n y su proyecto sobre tortugas marinas la llevaron a destacar en un concurso, lo que le abri√≥ las puertas a una oportunidad laboral en una reserva natural. Luna es un ejemplo de que con esfuerzo y perseverancia se pueden alcanzar los sue√±os.\n"
     ]
    }
   ],
   "source": [
    "# Genera preguntas\n",
    "pregunta = \"¬øQuien es Luna?\"\n",
    "\n",
    "# Instruscciones \n",
    "\n",
    "system_prompt = \"Tu tarea es responder las preguntas utilizando el contexto como base de informacion\"\n",
    "\n",
    "prompt = f\"\"\" \n",
    "            ###\n",
    "            Instrucciones: \n",
    "            - Responde la pregunta utilizado el contexto.\n",
    "\n",
    "            ###\n",
    "            Contexto:\n",
    "            {historia}\n",
    "\n",
    "            ###\n",
    "            Pregunta:\n",
    "            {pregunta}\n",
    "\n",
    "            \"\"\"\n",
    "\n",
    "response = co.chat(\n",
    "    model=\"command-r-plus-08-2024\",\n",
    "    messages=[\n",
    "        {\"role\": \"system\", \"content\":system_prompt},\n",
    "        {\"role\": \"user\", \"content\": prompt}\n",
    "    ],\n",
    ")\n",
    "\n",
    "print(response.message.content[0].text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "550978bd-9e00-48aa-9929-c7e7119e205c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Luna es una joven so√±adora üåô que logr√≥ su meta de trabajar en conservaci√≥n animal. ü¶é\n"
     ]
    }
   ],
   "source": [
    "# segunda iteracion (agrego mas instrucciones)\n",
    "\n",
    "prompt = f\"\"\" \n",
    "            ###\n",
    "            Instrucciones: \n",
    "            - Responde la pregunta utilizado el contexto.\n",
    "            - Responde de manera concisa, en una sola oracion.\n",
    "            - Agrega emojis relacionados en la respuesta.\n",
    "\n",
    "            ###\n",
    "            Contexto:\n",
    "            {historia}\n",
    "\n",
    "            ###\n",
    "            Pregunta:\n",
    "            {pregunta}\n",
    "\n",
    "            \"\"\"\n",
    "\n",
    "response = co.chat(\n",
    "    model=\"command-r-plus-08-2024\",\n",
    "    messages=[\n",
    "        {\"role\": \"system\", \"content\":system_prompt},\n",
    "        {\"role\": \"user\", \"content\": prompt}\n",
    "    ],\n",
    ")\n",
    "\n",
    "\n",
    "print(response.message.content[0].text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "20c7c2e9-2fd6-4bd7-aabf-3e7f25f5ffaf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Luna √©tudie la biologie tout en s'occupant de son jeune fr√®re. üåüüê¢\n"
     ]
    }
   ],
   "source": [
    "# tercera iteracion (agrego mas instrucciones)\n",
    "pregunta = \"Qu'√©tudie Luna?\"\n",
    "prompt = f\"\"\" \n",
    "            ###\n",
    "            Instrucciones: \n",
    "            - Responde la pregunta utilizado el contexto.\n",
    "            - Responde de manera concisa, en una sola oracion.\n",
    "            - Agrega emojis relacionados en la respuesta.\n",
    "            - Responde en tercera persona\n",
    "            - *Importante: Responde en el mismo idioma en que est√° escrita la pregunta.*\n",
    "\n",
    "            Ejemplo 1:\n",
    "            Pregunta: \"¬øQu√© hace Luna?\"\n",
    "            Respuesta: \"Ella estudia arte üé®‚ú®.\"\n",
    "\n",
    "            Ejemplo 2:\n",
    "            Pregunta: \"What does Luna study?\"\n",
    "            Respuesta: \"She studies art üé®‚ú®.\"\n",
    "\n",
    "\n",
    "            ###\n",
    "            Contexto:\n",
    "            {historia}\n",
    "\n",
    "            ###\n",
    "            Pregunta:\n",
    "            {pregunta}\n",
    "\n",
    "            \"\"\"\n",
    "\n",
    "response = co.chat(\n",
    "    model=\"command-r-plus-08-2024\",\n",
    "    messages=[\n",
    "        {\"role\": \"system\", \"content\":system_prompt},\n",
    "        {\"role\": \"user\", \"content\": prompt}\n",
    "    ],\n",
    ")\n",
    "\n",
    "\n",
    "print(response.message.content[0].text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab596f9a-2668-477d-a477-42651d1d4fe8",
   "metadata": {},
   "source": [
    "### Idiomas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb4a4001-082c-40fa-9198-1b234dcd2804",
   "metadata": {},
   "outputs": [],
   "source": [
    "Implementar una solucion utilizando el modelo command para que siempre se le responda al usuario en espanol.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b89874ef-107b-480e-9859-6e940e9463f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# formato\n",
    "\n",
    "def responde_espanol(consulta):\n",
    "    response = co.chat(\n",
    "        model=\"command\",\n",
    "        messages=[\n",
    "            {\"role\": \"system\", \"content\":\"Responde siempre en espa√±ol\"},\n",
    "            {\"role\": \"user\", \"content\": consulta}\n",
    "        ],\n",
    "    )\n",
    "    return response.message.content[0].text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5159aea8-6e75-46f6-a8a5-1682ee0b1636",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'A sopita is a type of Spanish soup, which is a dish that is served warm and consists of various ingredients such as meats, vegetables, beans, and grains that have been boiled in a liquid base such as water, stock, or broth. \\n\\nSopita is often used as a remedy for ailments like the common cold in many Spanish-speaking countries. \\n\\nThere are many different sopita recipes, but some of the most popular ingredients include chicken, rice, vegetables, and herbs like parsley and oregano. \\n\\nIt is a delicious and comforting food that can be eaten at any time of year but is particularly appealing during winter months or in cooler climates.'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "responde_espanol('que es la sopita?')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "73286692-ad56-49d5-9836-a555deb47588",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TIP\n",
    "# Algunos modelos no son optimos para responder en varios lenguajes, y puede que con una sola instruccion por prompt no sea suficiente.\n",
    "# Podemos utilizar varios tiros al endpoint del chat para ir reformulando la respuesta paso a paso\n",
    "\n",
    "# solucion, dos llamadas al llm , una para generar la respuesta, otra para traducirla\n",
    "\n",
    "def responde_espanol(consulta):\n",
    "    \n",
    "    # genero la respuesta\n",
    "    response = co.chat(\n",
    "        model=\"command\",\n",
    "        messages=[\n",
    "            {\"role\": \"system\", \"content\":\"Responde siempre en espa√±ol\"},\n",
    "            {\"role\": \"user\", \"content\": consulta}\n",
    "        ],\n",
    "    )\n",
    "\n",
    "    texto_respuesta = response.message.content[0].text\n",
    "    \n",
    "    # traduzco la respuesta\n",
    "    prompt = f\"\"\"Traducir al espanol siguiente texto\n",
    "    \n",
    "    texto: ''' {texto_respuesta} ''' \n",
    "\n",
    "    texto traducido:\n",
    "    \"\"\"\n",
    "    \n",
    "    response = co.chat(\n",
    "        model=\"command\",\n",
    "        messages=[\n",
    "            {\"role\": \"system\", \"content\":\"Actua como un traductor profesional, tu tarea es traducir al espa√±ol\"},\n",
    "            {\"role\": \"user\", \"content\": prompt}\n",
    "        ],\n",
    "    )\n",
    "    return response.message.content[0].text\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ea263eda-c2b8-40d6-9126-9f48edc25791",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Translated text:\\n\\n'A sopa es un tipo de sopa espa√±ola, un platillo preparado con diversos ingredientes, como verduras, carnes, legumbres y cereales cocidos en un caldo (normalmente se prepare con agua, caldo o leche y especias). \\n\\nSopa es una versi√≥n m√°s espesa que la sopa y es considerada un plato m√°s sustentable. \\n\\nEste platillo es muy popular en Latinoam√©rica y muchos pa√≠ses tienen su propia variaci√≥n espec√≠fica. \\n\\nNormalmente se consume durante el invierno, pero se disfruta todo el a√±o como un plato staple. '\""
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "responde_espanol('que es la sopita?')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1315c6de-7de9-4b80-8aca-e1eda118d2c1",
   "metadata": {},
   "source": [
    "#### Integracion de llamada del LLM al chatbot\n",
    "\n",
    "Integrar la llamada al LLM dentro del chatbot para que responda lo que el usuario le pregunte."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d79f7184-0e69-40c3-ace1-a8c87018239a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Crear widgets de entrada y salida\n",
    "input_box = widgets.Text(placeholder='Escribe tu mensaje aqu√≠...')\n",
    "send_button = widgets.Button(description='Enviar')\n",
    "output_box = widgets.Output()\n",
    "\n",
    "\n",
    "# Funci√≥n de respuesta simulada del chatbot\n",
    "def chatbot_response(message):\n",
    "    # Aqu√≠ puedes conectar tu modelo o l√≥gica de chatbot real\n",
    "    responses = {\n",
    "        \"hola\": \"¬°Hola! ¬øEn qu√© puedo ayudarte?\",\n",
    "        \"adi√≥s\": \"¬°Hasta luego!\",\n",
    "    }\n",
    "    return responses.get(message.lower(), \"Lo siento, no entiendo esa pregunta.\")\n",
    "\n",
    "# Funci√≥n de manejo del bot√≥n\n",
    "def on_send_button_clicked(b):\n",
    "    with output_box:\n",
    "        clear_output(wait=True)\n",
    "        user_message = input_box.value\n",
    "        if user_message.strip():\n",
    "            print(f\"T√∫: {user_message}\")\n",
    "            response = chatbot_response(user_message)\n",
    "            print(f\"Chatbot: {response}\")\n",
    "        input_box.value = ''\n",
    "\n",
    "# Asociar funci√≥n al bot√≥n\n",
    "send_button.on_click(on_send_button_clicked)\n",
    "\n",
    "# Mostrar widgets\n",
    "display(input_box, send_button, output_box)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40875ef2-0f4c-4c80-9cfa-6ef6537252b7",
   "metadata": {},
   "source": [
    "Ahora como proximo paso darle personalidad al bot, la que ustedes quieran.\n",
    "\n",
    "Puede ser que responda amigable, que responda explicando conceptos como un profesor, etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "37b7862b-a1db-42d7-9537-85757c96ce5b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a8928b6fbd1a4c629b621a6e93032e70",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Text(value='', placeholder='Escribe tu mensaje aqu√≠...')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7d1cf413714742888071841224a60247",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Button(description='Enviar', style=ButtonStyle())"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6f8d2801561d4d54b74c53e859e43ccc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# resolucion\n",
    "\n",
    "# simplemente debemos cambiar el bloque del chatbot response por el llm como veniamos trabajando en ejercicios anteriores\n",
    "# para darle personalidad podemos usar el system!!\n",
    "\n",
    "\n",
    "# Crear widgets de entrada y salida\n",
    "input_box = widgets.Text(placeholder='Escribe tu mensaje aqu√≠...')\n",
    "send_button = widgets.Button(description='Enviar')\n",
    "output_box = widgets.Output()\n",
    "\n",
    "\n",
    "# Funci√≥n de respuesta simulada del chatbot\n",
    "def chatbot_response(message):\n",
    "    response = co.chat(\n",
    "        model=\"command-r-plus-08-2024\",\n",
    "        messages=[\n",
    "            {\"role\": \"system\", \"content\":\"Responde de manera amigable, con emojis y simulando ser una chica gamer\"},\n",
    "            {\"role\": \"user\", \"content\": message}\n",
    "        ],\n",
    "    )\n",
    "\n",
    "    return response.message.content[0].text\n",
    "\n",
    "# Funci√≥n de manejo del bot√≥n\n",
    "def on_send_button_clicked(b):\n",
    "    with output_box:\n",
    "        clear_output(wait=True)\n",
    "        user_message = input_box.value\n",
    "        if user_message.strip():\n",
    "            print(f\"T√∫: {user_message}\")\n",
    "            response = chatbot_response(user_message)\n",
    "            print(f\"Chatbot: {response}\")\n",
    "        input_box.value = ''\n",
    "\n",
    "# Asociar funci√≥n al bot√≥n\n",
    "send_button.on_click(on_send_button_clicked)\n",
    "\n",
    "# Mostrar widgets\n",
    "display(input_box, send_button, output_box)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c17096d6-2fcd-41e5-a6da-0b2685dc3726",
   "metadata": {},
   "outputs": [],
   "source": [
    "Me parecio genial hacer esto!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
