{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "92de8ca4-7181-45f5-9980-b723d2566f5e",
   "metadata": {},
   "source": [
    "# Challenge Prompting\n",
    "\n",
    "Resolver los siguientes ejercicios dejando el codigo con su ejecucion.\n",
    "\n",
    "Importar las librerias necesarias y **correr las celdas para visualizar el resultado en cada ejercicio**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d65bbb09-0f5a-4e97-9a06-2361c5cdd1bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "## bloque importacion de librerias\n",
    "\n",
    "import json\n",
    "import ipywidgets as widgets\n",
    "from IPython.display import display, clear_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e004e5b7-b704-4592-b8b4-b01b8d6687cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "419ZWKkfbVtyWRwvaRoa9nqWhB2xdfJdmJHlNRFG\n"
     ]
    }
   ],
   "source": [
    "## bloque variables de entorno\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "\n",
    "load_dotenv()  # Load .env file\n",
    "\n",
    "api_key = os.getenv(\"COHERE_API_KEY\")\n",
    "print(api_key)  # Verify the key is loaded\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cd6745ff-cd45-4231-b3d6-518954a9ffca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "id='3a8aaab3-2c32-4868-b5f9-392b035ca02c' finish_reason='COMPLETE' prompt=None message=AssistantMessageResponse(role='assistant', tool_calls=None, tool_plan=None, content=[TextAssistantMessageResponseContentItem(type='text', text='Hello! How can I help you today?')], citations=None) usage=Usage(billed_units=UsageBilledUnits(input_tokens=3.0, output_tokens=9.0, search_units=None, classifications=None), tokens=UsageTokens(input_tokens=204.0, output_tokens=9.0)) logprobs=None\n"
     ]
    }
   ],
   "source": [
    "## bloque conexion a Cohere\n",
    "import cohere\n",
    "\n",
    "co = cohere.ClientV2()\n",
    "# alternativa:\n",
    "# co = cohere.ClientV2(api_key)\n",
    "\n",
    "response = co.chat(\n",
    "    model=\"command-r-plus-08-2024\",\n",
    "    messages=[{\"role\": \"user\", \"content\": \"hello world!\"}],\n",
    ")\n",
    "\n",
    "print(response)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9aacdb26-ce51-49cc-b37f-5aa45c09ff51",
   "metadata": {},
   "source": [
    "## Ejercicio 1\n",
    "\n",
    "Extraccion de entidades\n",
    "\n",
    "Utilizar el LLM para extraer las siguientes entidades del texto medico.\n",
    "\n",
    "- Paciente:\n",
    "    - Nombre\n",
    "    - Edad\n",
    "- Fecha de admisión\n",
    "- Síntomas\n",
    "- Diagnóstico\n",
    "- Tratamiento recomendado\n",
    "\n",
    "**Aclaracion:** \n",
    "\n",
    "La salida tiene que ser un **string con formato de tipo json**, el cual se convertira en un diccionario de Python.\n",
    "\n",
    "Si la linea de conversion en test da error el ejercicio no esta completo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "750e43d7-b074-4973-9cd0-5a6fbe816084",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ejemplo \n",
    "\n",
    "# texto a analizar\n",
    "\"\"\"La paciente, María González, de 45 años, fue admitida en el Hospital Central el 5 de agosto de 2023 debido a síntomas de fatiga crónica y dolores musculares./\n",
    "Tras una serie de análisis, se diagnosticó fibromialgia. La doctora a cargo, Laura Ramírez, recomendó un tratamiento basado en fisioterapia y medicamentos analgésicos. /\n",
    "La próxima consulta está programada para el 15 de septiembre.\"\"\"\n",
    "\n",
    "\n",
    "# respuesta del LLM\n",
    "{\n",
    "  \"paciente\": {\n",
    "    \"nombre\": \"María González\",\n",
    "    \"edad\": 45\n",
    "  },\n",
    "  \"fecha_admision\": \"2023-08-05\",\n",
    "  \"sintomas\": [\n",
    "    \"fatiga crónica\",\n",
    "    \"dolores musculares\"\n",
    "  ],\n",
    "  \"diagnostico\": \"fibromialgia\",\n",
    "  \"tratamiento\": [\n",
    "    \"fisioterapia\",\n",
    "    \"medicamentos analgésicos\"\n",
    "  ]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ac8d0a6-db5c-4eec-9f71-89e60ceaf914",
   "metadata": {},
   "outputs": [],
   "source": [
    "#####\n",
    "\n",
    "# imprimir la respuesta\n",
    "llm_response = response.message.content[0].text\n",
    "print(llm_response)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "425cffab-9efd-4d80-bc64-6ef69ce233e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "text_to_analize = \"\"\"Elena Ruiz, de 55 años, fue diagnosticada el 18 de enero de 2023 con diabetes tipo 2 después de presentar niveles elevados de glucosa en sangre durante un examen. \n",
    "Los síntomas incluyen sed excesiva y aumento en la frecuencia urinaria. El tratamiento recomendado incluye medicamentos orales y monitoreo frecuente de los niveles de glucosa. \n",
    "La próxima cita para evaluación será el 25 de enero.\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "2ff6d292-d4cb-4484-811e-d0d641c66d1c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "f-string: single '}' is not allowed (2449162443.py, line 11)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  Cell \u001b[1;32mIn[14], line 11\u001b[1;36m\u001b[0m\n\u001b[1;33m    },\u001b[0m\n\u001b[1;37m    ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m f-string: single '}' is not allowed\n"
     ]
    }
   ],
   "source": [
    "# your code here\n",
    "system_prompt = \"Tu tarea es proporcionar información en formato JSON basada en el contexto proporcionado, si no tenes esa informacion devolve vacio\"\n",
    "\n",
    "prompt = f\"\"\" \n",
    "            ###\n",
    "            Formato de Salida:\n",
    "            {{\n",
    "              \"paciente\": {{\n",
    "                \"nombre\": \"María González\",\n",
    "                \"edad\": 45\n",
    "              },\n",
    "              \"fecha_admision\": \"2023-08-05\",\n",
    "              \"sintomas\": [\n",
    "                \"fatiga crónica\",\n",
    "                \"dolores musculares\"\n",
    "              ],\n",
    "              \"diagnostico\": \"fibromialgia\",\n",
    "              \"tratamiento\": [\n",
    "                \"fisioterapia\",\n",
    "                \"medicamentos analgésicos\"\n",
    "              ]\n",
    "            }\n",
    "\n",
    "            ###\n",
    "            Contexto:\n",
    "            {text_to_analize}\n",
    "            \n",
    "            \"\"\"\n",
    "\n",
    "response = co.chat(\n",
    "    model=\"command-r-plus-08-2024\",\n",
    "    messages=[\n",
    "        {\"role\": \"system\", \"content\":system_prompt},\n",
    "        {\"role\": \"user\", \"content\": prompt}\n",
    "    ],\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "6f6f0009-8a9c-49a3-b740-d73e0dbe765e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'paciente': {'nombre': 'Elena Ruiz', 'edad': 55}, 'fecha_admision': '2023-01-18', 'sintomas': ['Sed excesiva', 'Aumento en la frecuencia urinaria'], 'diagnóstico': 'Diabetes tipo 2', 'tratamiento': ['Medicamentos orales', 'Monitoreo frecuente de niveles de glucosa']}\n"
     ]
    }
   ],
   "source": [
    "# test\n",
    "\n",
    "final_result = json.loads(llm_response)\n",
    "print(final_result)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b37fbf25-6db4-432a-82c4-2e7edce27686",
   "metadata": {},
   "source": [
    "## Ejercicio 2\n",
    "\n",
    "Tenemos dos funciones en Python, una llamada *'add_contact'* y otra llamada *'get_information'*.\n",
    "\n",
    "**Utilizar algun LLM que permita funtion calling** y desarrollar un codigo secuencial automatico que consiga:\n",
    "\n",
    "Interpretar la consulta del usuario, identificar a que funcion llamar, luego llamarla (si es que aplica) y darle una respuesta final al usuario.  (usar function calling para esta solucion)\n",
    "\n",
    "La entrada a dicho codigo es la consulta del usuario, a continuacion algunos ejemplos:\n",
    "\n",
    "- \"Agrega a Juan Pérez con el número 555-1234 y el correo juanperez@mail.com.\"\n",
    "- \"Guarda a Lucía Gómez en mis contactos. Su teléfono es 555-5678 y su email es lucia.gomez@gmail.com.\"\n",
    "- \"Cual es el Email de Juan Pérez.?\"\n",
    "\n",
    "Salidas esperadas de dichos ejemplos (variaran porque las genera el LLM):\n",
    "-  El contacto fue anadido con exito\n",
    "-  Se anadio el contacto\n",
    "-  El email de juan perez es juanperez@mail.com\n",
    "\n",
    "Link de ayuda: https://github.com/cohere-ai/notebooks/blob/main/notebooks/agents/Vanilla_Tool_Use_v2.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "c6e43cb9-5e6a-4807-9818-c85408f1ba58",
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_contact(name, phone, email):\n",
    "    \"\"\"\n",
    "    Agrega un contacto al diccionario.\n",
    "    Parámetros:\n",
    "        name (str): Nombre del contacto.\n",
    "        phone (str): Número de teléfono del contacto.\n",
    "        email (str): Correo electrónico del contacto.\n",
    "    Retorna:\n",
    "        str: Mensaje confirmando la adición del contacto.\n",
    "    \"\"\"\n",
    "    contacts[name] = {'phone': phone, 'email': email}\n",
    "    return \"Contacto añadido con éxito.\"\n",
    "\n",
    "def get_information(name):\n",
    "    \"\"\"\n",
    "    Recupera la información de un contacto.\n",
    "    Parámetros:\n",
    "        name (str): Nombre del contacto.\n",
    "    Retorna:\n",
    "        dict/str: Información del contacto o un mensaje si no existe.\n",
    "    \"\"\"\n",
    "    if name in contacts:\n",
    "        return contacts[name]\n",
    "    else:\n",
    "        return \"Contacto no encontrado.\"\n",
    "\n",
    "funcion_map = {\"add_contact\": add_contact,\n",
    "               \"get_information\": get_information}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "0fb79ea5-4ae3-4367-8213-8c38059b3f1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "contacts = {\n",
    "                        'Joaquin Lopez':{'tel': 15456663258, 'mail': 'Joacolocolopez@gmail.com'},\n",
    "                      'Flavio Oncativo':{'tel': 1545554178, 'mail': 'FOncativo@hotmail.com'}\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "6f8a3b4c-dc00-4cb8-bd0a-a3104852a47c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Descripción de herramientas que el modelo tiene acceso\n",
    "tools = [\n",
    "    {\n",
    "        \"type\": \"function\",\n",
    "        \"function\": {\n",
    "            \"name\": \"add_contact\",\n",
    "            \"description\": \"Agrega un nuevo contacto al diccionario con su nombre, teléfono y correo electrónico.\",\n",
    "            \"parameters\": {\n",
    "                \"type\": \"object\",\n",
    "                \"properties\": {\n",
    "                    \"name\": {\n",
    "                        \"type\": \"string\",\n",
    "                        \"description\": \"El nombre del contacto.\"\n",
    "                    },\n",
    "                    \"phone\": {\n",
    "                        \"type\": \"string\",\n",
    "                        \"description\": \"El número de teléfono del contacto.\"\n",
    "                    },\n",
    "                    \"email\": {\n",
    "                        \"type\": \"string\",\n",
    "                        \"description\": \"El correo electrónico del contacto.\"\n",
    "                    }\n",
    "                },\n",
    "                \"required\": [\"name\", \"phone\", \"email\"]\n",
    "            }\n",
    "        }\n",
    "    },\n",
    "    {\n",
    "        \"type\": \"function\",\n",
    "        \"function\": {\n",
    "            \"name\": \"get_information\",\n",
    "            \"description\": \"Recupera la información de un contacto basado en su nombre.\",\n",
    "            \"parameters\": {\n",
    "                \"type\": \"object\",\n",
    "                \"properties\": {\n",
    "                    \"name\": {\n",
    "                        \"type\": \"string\",\n",
    "                        \"description\": \"El nombre del contacto cuya información se desea obtener.\"\n",
    "                    }\n",
    "                },\n",
    "                \"required\": [\"name\"]\n",
    "            }\n",
    "        }\n",
    "    }\n",
    "]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "0021ca54-df71-4f60-bf63-4526c7087b0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preamble (Introducción) que contiene instrucciones sobre la tarea y el estilo deseado para la salida\n",
    "preamble = \"\"\"\n",
    "## Tarea y Contexto\n",
    "Tu tarea es ayudar a gestionar contactos. El sistema te permitirá agregar contactos con su nombre, número de teléfono y correo electrónico. También podrás recuperar la información de los contactos que se han agregado al sistema. Debes responder de manera eficiente y clara, proporcionando los detalles correctos de acuerdo a la solicitud del usuario.\n",
    "\n",
    "## Guía de Estilo\n",
    "A menos que el usuario indique lo contrario, debes responder en oraciones completas y con gramática correcta. Cuando se agregue un contacto, confirma la operación. Si un contacto no se encuentra, informa al usuario de manera clara.\n",
    "\"\"\"\n",
    "\n",
    "# Solicitud del usuario\n",
    "message = \"¿Puedes agregar a Mara con el teléfono 1234567890 y el correo mara@ejemplo.com, y luego proporcionarme la información de contacto de Mara?\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "a1bca466-f9b8-4171-bb4a-5b05730f942a",
   "metadata": {},
   "outputs": [],
   "source": [
    "messages = [\n",
    "    {\"role\": \"system\", \"content\": preamble},\n",
    "    {\"role\": \"user\", \"content\": message}\n",
    "]\n",
    "\n",
    "# Llamada al modelo para procesar la solicitud\n",
    "response = co.chat(\n",
    "    model=\"command-r-plus\",\n",
    "    messages=messages,\n",
    "    tools=tools\n",
    ")\n",
    "    \n",
    "# Actualizar el historial de mensajes con las llamadas a herramientas realizadas\n",
    "messages.append({'role': 'assistant', 'tool_calls': response.message.tool_calls, 'tool_plan': response.message.tool_plan})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "id": "fb41576c-7f55-47b0-92fa-d3116dbacf33",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Resultados de las herramientas que serán alimentados de vuelta al modelo:\n",
      "\"Contacto a\\u00f1adido con \\u00e9xito.\"\n"
     ]
    }
   ],
   "source": [
    "tool_content = []\n",
    "# Iterar sobre las llamadas a las herramientas generadas por el modelo\n",
    "for tc in response.message.tool_calls:\n",
    "    # Llamar a la herramienta recomendada por el modelo, usando los parámetros recomendados\n",
    "    tool_result = funcion_map[tc.function.name](**json.loads(tc.function.arguments))\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    ####ACA me falta el for\n",
    "    # Almacenar el resultado en una lista\n",
    "    tool_content.append(json.dumps(tool_result))\n",
    "    \n",
    "    # Actualizar el historial de mensajes\n",
    "    # Simulamos el historial de mensajes, añadiendo la llamada a la herramienta\n",
    "    messages.append({'role': 'tool', 'tool_call_id': tc.id, 'tool_content': tool_content})\n",
    "\n",
    "# Imprimir los resultados de las herramientas ARREGLAR EL PRINT\n",
    "print(\"Resultados de las herramientas que serán alimentados de vuelta al modelo:\")\n",
    "for result in tool_content:\n",
    "    print(json.dumps(json.loads(result), indent=2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "5b25c327-5834-4d62-93c6-8473a9b5a820",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ChatResponse(id='5e5bbe0c-1855-49e8-bd38-42e238a83a3c', finish_reason='COMPLETE', prompt=None, message=AssistantMessageResponse(role='assistant', tool_calls=None, tool_plan=None, content=[TextAssistantMessageResponseContentItem(type='text', text='Hello! How can I help you today?')], citations=None), usage=Usage(billed_units=UsageBilledUnits(input_tokens=3.0, output_tokens=9.0, search_units=None, classifications=None), tokens=UsageTokens(input_tokens=204.0, output_tokens=9.0)), logprobs=None)"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "id": "f90097df-4e32-474a-bf5e-cc566a53d595",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Función para extraer el nombre de la consulta del usuario\n",
    "def extract_name(user_query):\n",
    "    response = co.chat(\n",
    "        model=\"command\",\n",
    "        messages=[\n",
    "            {\"role\": \"system\", \"content\": \"Extrae el nombre de la consulta de manera precisa. El nombre será la persona mencionada después de palabras como 'agrega a' o 'guarda a'.\"},\n",
    "            {\"role\": \"user\", \"content\": user_query}\n",
    "        ],\n",
    "    )\n",
    "   # Acceder al contenido en el primer elemento del atributo 'content'\n",
    "    if response.message and response.message.content:\n",
    "        content_list = response.message.content  # Lista de objetos de tipo TextAssistantMessageResponseContentItem\n",
    "        if isinstance(content_list, list) and len(content_list) > 0:\n",
    "            name = content_list[0].text.strip()  # Accede al texto del primer elemento\n",
    "        else:\n",
    "            name = \"No se pudo extraer un nombre válido.\"\n",
    "    else:\n",
    "        name = \"No se pudo extraer un nombre válido.\"\n",
    "    \n",
    "    return name\n",
    "\n",
    "# Función para extraer el teléfono de la consulta del usuario\n",
    "def extract_phone(user_query):\n",
    "    response = co.chat(\n",
    "        model=\"command\",\n",
    "        messages=[\n",
    "            {\"role\": \"system\", \"content\": \"Extrae el número de teléfono mencionado en la consulta del usuario. Si no hay ninguno, indícalo explícitamente.\"},\n",
    "            {\"role\": \"user\", \"content\": user_query}\n",
    "        ],\n",
    "    )\n",
    "    # Acceder al contenido en el primer elemento del atributo 'content'\n",
    "    if response.message and response.message.content:\n",
    "        content_list = response.message.content  # Lista de objetos de tipo TextAssistantMessageResponseContentItem\n",
    "        if isinstance(content_list, list) and len(content_list) > 0:\n",
    "            phone = content_list[0].text.strip()  # Accede al texto del primer elemento\n",
    "        else:\n",
    "            phone = \"No se pudo extraer un número de teléfono válido.\"\n",
    "    else:\n",
    "        phone = \"No se pudo extraer un número de teléfono válido.\"\n",
    "    \n",
    "    return phone\n",
    "\n",
    "\n",
    "# Función para extraer el mail de la consulta del usuario\n",
    "def extract_email(user_query):\n",
    "    response = co.chat(\n",
    "        model=\"command\",\n",
    "        messages=[\n",
    "            {\"role\": \"system\", \"content\": \"Extrae el correo electrónico mencionado en la consulta del usuario. Si no hay ninguno, indícalo explícitamente.\"},\n",
    "            {\"role\": \"user\", \"content\": user_query}\n",
    "        ],\n",
    "    )\n",
    "    # Acceder al contenido en el primer elemento del atributo 'content'\n",
    "    if response.message and response.message.content:\n",
    "        content_list = response.message.content  # Lista de objetos de tipo TextAssistantMessageResponseContentItem\n",
    "        if isinstance(content_list, list) and len(content_list) > 0:\n",
    "            email = content_list[0].text.strip()  # Accede al texto del primer elemento\n",
    "        else:\n",
    "            email = \"No se pudo extraer un correo válido.\"\n",
    "    else:\n",
    "        email = \"No se pudo extraer un correo válido.\"\n",
    "    \n",
    "    return email\n",
    "\n",
    "\n",
    "\n",
    "# Función para procesar la consulta del usuario y decidir qué acción tomar\n",
    "def process_query_with_model(user_query):\n",
    "    # Verificar si el usuario está solicitando información sobre un contacto\n",
    "    if \"email\" in user_query or \"correo\" in user_query:\n",
    "        # Buscar el nombre del contacto, este if podria sacarlo\n",
    "        name = extract_name(user_query)\n",
    "        if name == \"No se pudo extraer un nombre válido.\":\n",
    "            return name  # Devolver error si no se encontró un nombre\n",
    "\n",
    "        # Preparar el prompt con la lista de contactos y la consulta del usuario\n",
    "        prompt = f\"\"\"\n",
    "                Lista de contactos:\n",
    "                {contacts}\n",
    "\n",
    "                Pregunta del usuario:\n",
    "                {user_query}\n",
    "\n",
    "                Tarea: Responde de manera amable y clara con la información solicitada.\n",
    "                \"\"\"\n",
    "        \n",
    "        # Llamar al modelo para obtener una respuesta pruebo con \"Proporciona la información en formato amigable con base en la lista de contactos proporcionada.\"\n",
    "        response = co.chat(\n",
    "            model=\"command-r-plus-08-2024\",  \n",
    "            messages=[\n",
    "                {\"role\": \"system\", \"content\": \"Tu tarea es proporcionar en formato texto la información que está en formato JSON en la Lista de Contacto.\"},\n",
    "                {\"role\": \"user\", \"content\": prompt}\n",
    "            ]\n",
    "        )\n",
    "        \n",
    "        return response.message.content[0].text\n",
    "\n",
    "# pruebo con eso return response.choices[0].message['content'].strip() yo usaba este return response.message.content[0].text\n",
    "\n",
    "\n",
    "    elif \"agrega\" in user_query or \"guarda\" in user_query:\n",
    "        # Si la consulta es para agregar un contacto, extraer los datos\n",
    "        name = extract_name(user_query)\n",
    "        phone = extract_phone(user_query)\n",
    "        email = extract_email(user_query)\n",
    "\n",
    "         # Validar que se encontraron datos válidos porque no hice las otras funciones jaja te la creiste, si esta\n",
    "        if not all([name, phone, email]):\n",
    "            return \"No se pudieron extraer todos los datos necesarios para agregar el contacto.\"\n",
    "\n",
    "\n",
    "        # Agregar el contacto a la lista\n",
    "        contacts.append({\"name\": name, \"phone\": phone, \"email\": email})\n",
    "        return f\"El contacto {name} fue añadido con éxito.\"\n",
    "\n",
    "    else:\n",
    "        return \"Lo siento, no entendí tu consulta. Intenta reformularla.\"    \n",
    "        \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "id": "52070141-c7a1-42bc-878f-8ae5109f9c2a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "El correo electrónico de Flavio Oncativo es FOncativo@hotmail.com.\n"
     ]
    }
   ],
   "source": [
    "user_query = \"cual es el email de flavio?.\"\n",
    "response = process_query_with_model(user_query)\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c36ef67d-dd54-41e7-bef5-f89ee575603f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TIPS\n",
    "# Probar primero generando una funcion y llamarla, luego anadir la otra\n",
    "# Plantearlo paso por paso en distintas celdas, analizar las salidas y las entradas, como identificamos a que funcion llamar?\n",
    "# luego automatizar dentro de una sola celda\n",
    "\n",
    "\n",
    "# Lo importante es entregar hasta donde lleguen, sea una funcion, las dos pero sin poder hacer el flujo automatico, lo que puedan, siempre y cuando este\n",
    "# claro lo que se quizo hacer con comentarios."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca63da74-3acb-416b-93d5-5fa672f46939",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Simulamos agregar un nuevo contacto\n",
    "response_add = add_contact('Mara', '1234567890', 'mara@ejemplo.com')\n",
    "print(response_add)  # Debería imprimir: \"Contacto añadido con éxito.\"\n",
    "\n",
    "# Simulamos obtener la información del contacto agregado\n",
    "response_get = get_information('Mara')\n",
    "print(json.dumps(response_get, indent=2))  # Debería mostrar la información de Mara (teléfono y correo)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9d8badf-dc90-4005-b916-8e528105d797",
   "metadata": {},
   "source": [
    "## Ejercicio 3\n",
    "\n",
    "Crear una funcion llamada \"history_answer\", que toma como parametro de entrada una pregunta sobre un contexto dado y la salida es la respuesta final del proceso impulsado por un LLM.\n",
    "\n",
    "Dada una historia, el usuario podra hacer preguntas sobre la misma y el LLM debe responder siguiendo los siguientes lineamientos:\n",
    "\n",
    "REQUISITOS DE LA RESPUESTA\n",
    "- las respuestas deben ser en base a la historia\n",
    "- ante la misma pregunta siempre debe responder de la misma manera.\n",
    "- que responda en solo una oracion.\n",
    "- el idioma que responde debe ser el mismo que con el que se pregunta (ingles, espanol, portugues).\n",
    "- que agregue emojis en la oracion que resuman el contenido de la misma.\n",
    "- que responda siempre en tercera persona.\n",
    "- si la pregunta no tiene relacion alguna con el contexto, la respuesta debe ser 'Lo siento no puedo ayudarte con eso'.\n",
    "- Responder con 'Hakuna Matata!' al final de **todas** las respuestas (no importa idioma ni cantidad de tokens).\n",
    "\n",
    "**Ayudin**: \n",
    "- No se limiten a usar 1 solo request al LLM, pueden dividirlo en partes para que por un lado se verifique el idioma, por otro lado se verifique si la pregunta tiene relacion con el contexto, etc\n",
    "\n",
    "- Estructuren bien el prompt procurando separar instrucciones, contexto(historia) y pregunta del usuario.\n",
    "\n",
    "- Recuerden usar el system message y user message.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09f36820-b7d3-4813-a0c3-351c598106ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ejemplo flojo de estructura de prompt\n",
    "# prompt = f\"Responde a la pregunta: {pregunta} de manera concisa y divertida en base a la siguiente historia: {historia}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "c5602f56-4032-4cc6-a2c5-7b29cf2a2a5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def history_answer(pregunta):\n",
    "    \"\"\"\n",
    "    Responde preguntas basadas en una historia, siguiendo los lineamientos.\n",
    "    \n",
    "    Parámetros:\n",
    "    - pregunta (str): La pregunta que hace el usuario.\n",
    "    - historia (str): El contexto o historia sobre la que se basa la respuesta.\n",
    "\n",
    "    Retorna:\n",
    "    - str: Respuesta generada por el LLM en base a los lineamientos.\n",
    "    \"\"\"\n",
    "    prompt = f\"\"\"\n",
    "                ###\n",
    "                Lineamientos a seguir:\n",
    "                1- Responde únicamente en base a la historia.\n",
    "                2- Ante la misma pregunta, responde siempre de la misma manera.\n",
    "                3- Responde en solo una oración.\n",
    "                4- *Importante: Responde en el mismo idioma en que está escrita la pregunta.*\n",
    "            \n",
    "                        Ejemplo 1:\n",
    "                        Pregunta: \"¿Qué hace Luna?\"\n",
    "                        Respuesta: \"Ella estudia arte 🎨✨.\"\n",
    "            \n",
    "                        Ejemplo 2:\n",
    "                        Pregunta: \"What does Luna study?\"\n",
    "                        Respuesta: \"She studies art 🎨✨.\"\n",
    "                5- Agregua emojis en la oracion que resuman el contenido de la misma\n",
    "                6- Responde siempre en tercera persona\n",
    "                7- Si la pregunta no tiene relacion alguna con el contexto, la respuesta debe ser 'Lo siento no puedo ayudarte con eso'\n",
    "                8- Responde con 'Hakuna Matata!' al final de **todas** las respuestas (no importa idioma ni cantidad de tokens)\n",
    "\n",
    "                 ###\n",
    "                Responde a la siguiente pregunta de manera concisa y consistente:\n",
    "                {pregunta}\n",
    "                \n",
    "                ###\n",
    "                En base a la siguiente historia:\n",
    "                {historia}\n",
    "    \n",
    "                \"\"\"\n",
    "\n",
    "    response = co.chat(\n",
    "    model=\"command-r-plus-08-2024\",\n",
    "    messages=[\n",
    "        {\"role\": \"system\", \"content\":\"Eres un asistente que responde preguntas sobre una historia de manera concisa y consistente.\"},\n",
    "        {\"role\": \"user\", \"content\": prompt}\n",
    "        ],\n",
    "    )\n",
    "\n",
    "    respuesta = response.message.content[0].text.strip()\n",
    "    return respuesta\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "fd70793f-fac2-4026-85dc-684a2708398e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ChatResponse(id='5e5bbe0c-1855-49e8-bd38-42e238a83a3c', finish_reason='COMPLETE', prompt=None, message=AssistantMessageResponse(role='assistant', tool_calls=None, tool_plan=None, content=[TextAssistantMessageResponseContentItem(type='text', text='Hello! How can I help you today?')], citations=None), usage=Usage(billed_units=UsageBilledUnits(input_tokens=3.0, output_tokens=9.0, search_units=None, classifications=None), tokens=UsageTokens(input_tokens=204.0, output_tokens=9.0)), logprobs=None)"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "f3aaa967-d87f-45d9-9a72-6fc63afc931c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Thomas es un valiente campesino que se convirtió en soldado, enfrentando la guerra y la pérdida en el campo de batalla. 🗡️🛡️🌾 Hakuna Matata!\n"
     ]
    }
   ],
   "source": [
    "historia = \"\"\"En un pequeño feudo medieval, Thomas, un joven campesino de dieciséis años, trabajaba desde el amanecer en los campos de trigo del señor feudal. El sol apenas había salido cuando él ya había arado más de lo que sus manos podían soportar. La vida era dura, pero su familia dependía de la cosecha para pagar los impuestos y mantener su hogar de madera y paja.\n",
    "\n",
    "Un día, el feudo fue sacudido por noticias de guerra. El rey había llamado a todos los hombres en edad de luchar. Thomas sabía que, al igual que otros jóvenes, no tenía elección. Cambió la hoz por una lanza rudimentaria y se unió a la milicia local. Sin entrenamiento, fue empujado a un campo de batalla embarrado, donde el acero resonaba y los gritos de los hombres llenaban el aire.\n",
    "\n",
    "La batalla fue un caos. Thomas, con el corazón latiendo en su pecho como un tambor de guerra, apenas podía distinguir amigo de enemigo. Logró esquivar una espada, pero cayó al suelo, cubierto de lodo y sangre. Levantándose, vio cómo un compañero caía junto a él, sus ojos abiertos, vacíos.\n",
    "\n",
    "Cuando la batalla terminó, el silencio era tan profundo como el vacío que sentía. Thomas regresó al feudo, diferente, marcado por la muerte y la violencia. Su madre lo recibió con lágrimas en los ojos, pero él, con la mirada fija en el horizonte, sabía que la inocencia había quedado atrás, enterrada en aquel campo de batalla. La paz del feudo ya no era la misma; él tampoco.\"\"\"\n",
    "\n",
    "\n",
    "pregunta = \"who is thomas?\"\n",
    "\n",
    "\n",
    "# respuesta\n",
    "print(history_answer(pregunta))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "11b1638d-a58f-4167-9278-f8a595521cc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "## INTENTO DE DETECTOR me funciono pero lo voy a seguir trabajando\n",
    "def detectar_idioma(pregunta):\n",
    "    prompt_idioma = f\"Detecta el idioma de esta pregunta: {pregunta}\"\n",
    "    \n",
    "    response = co.chat(\n",
    "        model=\"command\",\n",
    "        messages=[\n",
    "            {\"role\": \"system\", \"content\": \"Tu tarea es detectar el idioma de la pregunta.\"},\n",
    "            {\"role\": \"user\", \"content\": prompt_idioma}\n",
    "        ]\n",
    "    )\n",
    "    \n",
    "    idioma = response.message.content[0].text.strip()\n",
    "    return idioma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "e1a78277-52d4-48e5-96ee-39e603d77eba",
   "metadata": {},
   "outputs": [],
   "source": [
    "## INTENTO DE TRADUCTOR me funciono pero lo voy a seguir trabajando\n",
    "def traductor(texto, idioma):\n",
    "    prompt_traduccion = f\"Traducir el siguiente texto al idioma {idioma}: {texto}\"\n",
    "    \n",
    "    response = co.chat(\n",
    "        model=\"command\",\n",
    "        messages=[\n",
    "            {\"role\": \"system\", \"content\": f\"Actúa como un traductor profesional, traduce el siguiente texto al idioma {idioma}.\"},\n",
    "            {\"role\": \"user\", \"content\": prompt_traduccion}\n",
    "        ]\n",
    "    )\n",
    "    \n",
    "    return response.message.content[0].text.strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "4fa65537-3aa6-43c6-87e9-86a689f8e1d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "## No me funciono pero lo voy a seguir trabajando\n",
    "\n",
    "def history_answer(pregunta):\n",
    "    \"\"\"\n",
    "    Responde preguntas basadas en una historia, siguiendo los lineamientos.\n",
    "    \n",
    "    Parámetros:\n",
    "    - pregunta (str): La pregunta que hace el usuario.\n",
    "    - historia (str): El contexto o historia sobre la que se basa la respuesta.\n",
    "\n",
    "    Retorna:\n",
    "    - str: Respuesta generada por el LLM en base a los lineamientos.\n",
    "    \"\"\"\n",
    "\n",
    "    # Detecta el idioma de la pregunta\n",
    "    idioma = detectar_idioma(pregunta)\n",
    "    \n",
    "    # Si no está en español, traduce la pregunta\n",
    "    if idioma != \"español\":\n",
    "        pregunta = traductor(pregunta, idioma)\n",
    "        \n",
    "    prompt = f\"\"\"\n",
    "    ###\n",
    "    Responde a la siguiente pregunta de manera concisa y consistente:\n",
    "    {pregunta}\n",
    "    \n",
    "    ###\n",
    "    En base a la siguiente historia:\n",
    "    {historia}\n",
    "    \n",
    "    Lineamientos:\n",
    "    - Responde únicamente en base a la historia.\n",
    "    - Ante la misma pregunta, responde siempre de la misma manera.\n",
    "    - Responde en solo una oración.\n",
    "    \"\"\"\n",
    "\n",
    "    response = co.chat(\n",
    "    model=\"command-r-plus-08-2024\",\n",
    "    messages=[\n",
    "        {\"role\": \"system\", \"content\":\"Eres un asistente que responde preguntas sobre una historia de manera concisa y consistente.\"},\n",
    "        {\"role\": \"user\", \"content\": prompt}\n",
    "        ],\n",
    "    )\n",
    "\n",
    "    respuesta = response.message.content[0].text.strip()\n",
    "    return respuesta\n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31f246d9-ec91-498a-a06a-172947316325",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "795f451e-6c12-4631-895f-fa6ac8f16b74",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "db6e9a7d-aa39-4a01-ba55-9a7f4ea39522",
   "metadata": {},
   "source": [
    "## Ejercicio 4\n",
    "\n",
    "Crear un chatbot sencillo impulsado por un LLM. \n",
    "\n",
    "Dicho bot esta destinado a un usuario final y debe cumplir las siguientes **condiciones en sus respuestas**:\n",
    "\n",
    "- Responder en no mas de 70 tokens.\n",
    "- Responder de manera positiva, con un tono entusiasta.\n",
    "- Responder con consejos útiles, como si fueras un tutor.\n",
    "\n",
    " \n",
    "**Otras consideraciones**:\n",
    "\n",
    "Respetar el formato de la interfaz provista por el ejercicio.\n",
    "\n",
    "Ademas agregar al codigo propuesto un historial de conversaciones para que el bot pueda mantener el hilo de lo que se esta hablando. Para probar no usen mas de 3 conversaciones anidadas para no enviarle tantos tokens.\n",
    "\n",
    "Dejar impreso en el notebook el historial de la conversacion."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5284210f-23a3-4db1-b315-db724a3bb3a5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "aa475fa8-e48b-423e-9006-7478a462129c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1085d9dec2fc4a0a97116e9294b8eef6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Text(value='', placeholder='Escribe tu mensaje aquí...')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f1c63cd64d904a509d86e947708efa36",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Button(description='Enviar', style=ButtonStyle())"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "29c81afa15284e069d492bda7de8d846",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Crear widgets de entrada y salida\n",
    "input_box = widgets.Text(placeholder='Escribe tu mensaje aquí...')\n",
    "send_button = widgets.Button(description='Enviar')\n",
    "output_box = widgets.Output()\n",
    "\n",
    "# chat_history = []\n",
    "\n",
    "# Función de respuesta simulada del chatbot\n",
    "def chatbot_response(message):\n",
    "    # Aquí puedes conectar tu modelo o lógica de chatbot real\n",
    "    responses = {\n",
    "        \"hola\": \"¡Hola! ¿En qué puedo ayudarte?\",\n",
    "        \"adiós\": \"¡Hasta luego!\",\n",
    "    }\n",
    "\n",
    "    return responses.get(message.lower(), \"Lo siento, no entiendo esa pregunta.\")\n",
    "\n",
    "# Función de manejo del botón\n",
    "def on_send_button_clicked(b):\n",
    "    with output_box:\n",
    "        clear_output(wait=True)\n",
    "        user_message = input_box.value\n",
    "        if user_message.strip():\n",
    "            print(f\"Tú: {user_message}\")\n",
    "            response = chatbot_response(user_message)\n",
    "            print(f\"Chatbot: {response}\")\n",
    "        input_box.value = ''\n",
    "\n",
    "# Asociar función al botón\n",
    "send_button.on_click(on_send_button_clicked)\n",
    "\n",
    "# Mostrar widgets\n",
    "display(input_box, send_button, output_box)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "436d5bce-0189-4ecd-a06d-fcc7a81315b5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a213283-3ef7-4df8-8b7f-3bb11d58362d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(conversation_history)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6fb6d6a-1c32-42e5-a1ee-d62b2bc0785a",
   "metadata": {},
   "source": [
    "### RECOMENDACIONES GENERALES\n",
    "\n",
    "No se confien probando con un par de respuestas y ya, hagan minimo 5 pruebas por ejercicio para asi tener mas chances de visualizar errores en la generacion del contenido.\n",
    "\n",
    "Prueben combinar LLMs con programacion convencional para los casos que vean convenientes (decisiones if else, respuestas estaticas, etc)\n",
    "\n",
    "Prueben con distintos modelos de Cohere, hay algunos optimizados para ciertas aplicaciones."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a3f2e37-bf32-43b7-8958-e39954a20fb1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
