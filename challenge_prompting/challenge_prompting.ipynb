{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "92de8ca4-7181-45f5-9980-b723d2566f5e",
   "metadata": {},
   "source": [
    "# Challenge Prompting\n",
    "\n",
    "Resolver los siguientes ejercicios dejando el codigo con su ejecucion.\n",
    "\n",
    "Importar las librerias necesarias y **correr las celdas para visualizar el resultado en cada ejercicio**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d65bbb09-0f5a-4e97-9a06-2361c5cdd1bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "## bloque importacion de librerias\n",
    "\n",
    "import json\n",
    "import ipywidgets as widgets\n",
    "from IPython.display import display, clear_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e004e5b7-b704-4592-b8b4-b01b8d6687cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "419ZWKkfbVtyWRwvaRoa9nqWhB2xdfJdmJHlNRFG\n"
     ]
    }
   ],
   "source": [
    "## bloque variables de entorno\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "\n",
    "load_dotenv()  # Load .env file\n",
    "\n",
    "api_key = os.getenv(\"COHERE_API_KEY\")\n",
    "print(api_key)  # Verify the key is loaded\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cd6745ff-cd45-4231-b3d6-518954a9ffca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "id='d29873a7-6456-4046-bb6f-e056f5f3db87' finish_reason='COMPLETE' prompt=None message=AssistantMessageResponse(role='assistant', tool_calls=None, tool_plan=None, content=[TextAssistantMessageResponseContentItem(type='text', text='Hello! How can I help you today?')], citations=None) usage=Usage(billed_units=UsageBilledUnits(input_tokens=3.0, output_tokens=9.0, search_units=None, classifications=None), tokens=UsageTokens(input_tokens=204.0, output_tokens=9.0)) logprobs=None\n"
     ]
    }
   ],
   "source": [
    "## bloque conexion a Cohere\n",
    "import cohere\n",
    "\n",
    "co = cohere.ClientV2()\n",
    "# alternativa:\n",
    "# co = cohere.ClientV2(api_key)\n",
    "\n",
    "response = co.chat(\n",
    "    model=\"command-r-plus-08-2024\",\n",
    "    messages=[{\"role\": \"user\", \"content\": \"hello world!\"}],\n",
    ")\n",
    "\n",
    "print(response)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9aacdb26-ce51-49cc-b37f-5aa45c09ff51",
   "metadata": {},
   "source": [
    "## Ejercicio 1\n",
    "\n",
    "Extraccion de entidades\n",
    "\n",
    "Utilizar el LLM para extraer las siguientes entidades del texto medico.\n",
    "\n",
    "- Paciente:\n",
    "    - Nombre\n",
    "    - Edad\n",
    "- Fecha de admisi√≥n\n",
    "- S√≠ntomas\n",
    "- Diagn√≥stico\n",
    "- Tratamiento recomendado\n",
    "\n",
    "**Aclaracion:** \n",
    "\n",
    "La salida tiene que ser un **string con formato de tipo json**, el cual se convertira en un diccionario de Python.\n",
    "\n",
    "Si la linea de conversion en test da error el ejercicio no esta completo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "750e43d7-b074-4973-9cd0-5a6fbe816084",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'paciente': {'nombre': 'Mar√≠a Gonz√°lez', 'edad': 45},\n",
       " 'fecha_admision': '2023-08-05',\n",
       " 'sintomas': ['fatiga cr√≥nica', 'dolores musculares'],\n",
       " 'diagnostico': 'fibromialgia',\n",
       " 'tratamiento': ['fisioterapia', 'medicamentos analg√©sicos']}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ejemplo \n",
    "\n",
    "# texto a analizar\n",
    "\"\"\"La paciente, Mar√≠a Gonz√°lez, de 45 a√±os, fue admitida en el Hospital Central el 5 de agosto de 2023 debido a s√≠ntomas de fatiga cr√≥nica y dolores musculares./\n",
    "Tras una serie de an√°lisis, se diagnostic√≥ fibromialgia. La doctora a cargo, Laura Ram√≠rez, recomend√≥ un tratamiento basado en fisioterapia y medicamentos analg√©sicos. /\n",
    "La pr√≥xima consulta est√° programada para el 15 de septiembre.\"\"\"\n",
    "\n",
    "\n",
    "# respuesta del LLM\n",
    "{\n",
    "  \"paciente\": {\n",
    "    \"nombre\": \"Mar√≠a Gonz√°lez\",\n",
    "    \"edad\": 45\n",
    "  },\n",
    "  \"fecha_admision\": \"2023-08-05\",\n",
    "  \"sintomas\": [\n",
    "    \"fatiga cr√≥nica\",\n",
    "    \"dolores musculares\"\n",
    "  ],\n",
    "  \"diagnostico\": \"fibromialgia\",\n",
    "  \"tratamiento\": [\n",
    "    \"fisioterapia\",\n",
    "    \"medicamentos analg√©sicos\"\n",
    "  ]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ac8d0a6-db5c-4eec-9f71-89e60ceaf914",
   "metadata": {},
   "outputs": [],
   "source": [
    "#####"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "425cffab-9efd-4d80-bc64-6ef69ce233e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "text_to_analize = \"\"\"Elena Ruiz, de 55 a√±os, fue diagnosticada el 18 de enero de 2023 con diabetes tipo 2 despu√©s de presentar niveles elevados de glucosa en sangre durante un examen. \n",
    "Los s√≠ntomas incluyen sed excesiva y aumento en la frecuencia urinaria. El tratamiento recomendado incluye medicamentos orales y monitoreo frecuente de los niveles de glucosa. \n",
    "La pr√≥xima cita para evaluaci√≥n ser√° el 25 de enero.\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ff3c6ec7-6377-4467-9f84-ba7ad4d2918f",
   "metadata": {},
   "outputs": [],
   "source": [
    "estructura = {\n",
    "                \"paciente\": {\n",
    "                \"nombre\":\"[Nombre del paciente]\",\n",
    "                \"edad\": 25\n",
    "                },\n",
    "                \"fecha_admision\":\"[aaaa-mm-dd]\",\n",
    "                \"sintomas\":[\n",
    "                    \"Sintoma1\",\n",
    "                    \"Sintoma2\"\n",
    "                ],\n",
    "                \"diagn√≥stico\":\"[Descripci√≥n del diagn√≥stico]\",\n",
    "                \"tratamiento\":[\n",
    "                    \"Tratamiento1\",\n",
    "                    \"Tratamiento2\" \n",
    "                    ]\n",
    "             }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c12366c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"paciente\": {\n",
      "    \"nombre\": \"[Nombre del paciente]\",\n",
      "    \"edad\": 25\n",
      "  },\n",
      "  \"fecha_admision\": \"[aaaa-mm-dd]\",\n",
      "  \"sintomas\": [\n",
      "    \"Sintoma1\",\n",
      "    \"Sintoma2\"\n",
      "  ],\n",
      "  \"diagn\\u00f3stico\": \"[Descripci\\u00f3n del diagn\\u00f3stico]\",\n",
      "  \"tratamiento\": [\n",
      "    \"Tratamiento1\",\n",
      "    \"Tratamiento2\"\n",
      "  ]\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "print(json.dumps(estructura, indent=2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "2ff6d292-d4cb-4484-811e-d0d641c66d1c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'paciente': {'nombre': 'Elena Ruiz', 'edad': 55}, 'fecha_admision': '2023-01-18', 'sintomas': ['Sed excesiva', 'Aumento en la frecuencia urinaria'], 'diagn√≥stico': 'Diabetes tipo 2', 'tratamiento': ['Medicamentos orales', 'Monitoreo frecuente de los niveles de glucosa']}\n"
     ]
    }
   ],
   "source": [
    "# your code here\n",
    "system_prompt = \"Sos un experto en extracci√≥n de datos m√©dicos, que extrae la informaci√≥n de 'text_to_analize', si no conoce el valor de atributo, devolverlo vacio\"\n",
    "\n",
    "prompt = f\"\"\" \n",
    "            ###\n",
    "            Instrucciones: \n",
    "            - Proporciona la informaci√≥n solicitada en formato JSON estricto, seg√∫n las instrucciones y el contexto proporcionado.\n",
    "            - Aseg√∫rate de que la salida sea un objeto JSON v√°lido.\n",
    "            - Sigue exactamente el formato especificado a continuaci√≥n.\n",
    "\n",
    "            ###\n",
    "            Contexto:\n",
    "            {text_to_analize}\n",
    "\n",
    "            ###\n",
    "            La salida tiene que ser en formato JSON con la siguiente estructura:\n",
    "            {json.dumps(estructura, indent=2)}\n",
    "            \n",
    "            \"\"\"\n",
    "\n",
    "response = co.chat(\n",
    "    model=\"command-r-plus-08-2024\",\n",
    "    messages=[\n",
    "        {\"role\": \"system\", \"content\":system_prompt},\n",
    "        {\"role\": \"user\", \"content\": prompt}\n",
    "    ],\n",
    "    \n",
    ")\n",
    "# Parsear la respuesta JSON\n",
    "try:\n",
    "    respuesta_json = json.loads(response.message.content[0].text.strip())\n",
    "    print(respuesta_json)\n",
    "except json.JSONDecodeError:\n",
    "    print(\"La respuesta no es un JSON v√°lido:\", response.message.content[0].text)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "6f6f0009-8a9c-49a3-b740-d73e0dbe765e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"paciente\": {\n",
      "    \"nombre\": \"Elena Ruiz\",\n",
      "    \"edad\": 55\n",
      "  },\n",
      "  \"fecha_admision\": \"2023-01-18\",\n",
      "  \"sintomas\": [\n",
      "    \"Sed excesiva\",\n",
      "    \"Aumento en la frecuencia urinaria\"\n",
      "  ],\n",
      "  \"diagn√≥stico\": \"Diabetes tipo 2\",\n",
      "  \"tratamiento\": [\n",
      "    \"Medicamentos orales\",\n",
      "    \"Monitoreo frecuente de los niveles de glucosa\"\n",
      "  ]\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "# test\n",
    "\n",
    "print(response.message.content[0].text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b37fbf25-6db4-432a-82c4-2e7edce27686",
   "metadata": {},
   "source": [
    "## Ejercicio 2\n",
    "\n",
    "Tenemos dos funciones en Python, una llamada *'add_contact'* y otra llamada *'get_information'*.\n",
    "\n",
    "**Utilizar algun LLM que permita funtion calling** y desarrollar un codigo secuencial automatico que consiga:\n",
    "\n",
    "Interpretar la consulta del usuario, identificar a que funcion llamar, luego llamarla (si es que aplica) y darle una respuesta final al usuario.  (usar function calling para esta solucion)\n",
    "\n",
    "La entrada a dicho codigo es la consulta del usuario, a continuacion algunos ejemplos:\n",
    "\n",
    "- \"Agrega a Juan P√©rez con el n√∫mero 555-1234 y el correo juanperez@mail.com.\"\n",
    "- \"Guarda a Luc√≠a G√≥mez en mis contactos. Su tel√©fono es 555-5678 y su email es lucia.gomez@gmail.com.\"\n",
    "- \"Cual es el Email de Juan P√©rez.?\"\n",
    "\n",
    "Salidas esperadas de dichos ejemplos (variaran porque las genera el LLM):\n",
    "-  El contacto fue anadido con exito\n",
    "-  Se anadio el contacto\n",
    "-  El email de juan perez es juanperez@mail.com\n",
    "\n",
    "Link de ayuda: https://github.com/cohere-ai/notebooks/blob/main/notebooks/agents/Vanilla_Tool_Use_v2.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c6e43cb9-5e6a-4807-9818-c85408f1ba58",
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_contact(name, phone, email):\n",
    "    \"\"\"\n",
    "    Agrega un contacto al diccionario.\n",
    "    Par√°metros:\n",
    "        name (str): Nombre del contacto.\n",
    "        phone (str): N√∫mero de tel√©fono del contacto.\n",
    "        email (str): Correo electr√≥nico del contacto.\n",
    "    Retorna:\n",
    "        str: Mensaje confirmando la adici√≥n del contacto.\n",
    "    \"\"\"\n",
    "    contacts[name] = {'phone': phone, 'email': email}\n",
    "    return \"Contacto a√±adido con √©xito.\"\n",
    "\n",
    "def get_information(name):\n",
    "    \"\"\"\n",
    "    Recupera la informaci√≥n de un contacto.\n",
    "    Par√°metros:\n",
    "        name (str): Nombre del contacto.\n",
    "    Retorna:\n",
    "        dict/str: Informaci√≥n del contacto o un mensaje si no existe.\n",
    "    \"\"\"\n",
    "    if name in contacts:\n",
    "        return contacts[name]\n",
    "    else:\n",
    "        return \"Contacto no encontrado.\"\n",
    "    \n",
    "funcion_map = {\n",
    "    \"add_contact\": add_contact,\n",
    "    \"get_information\": get_information\n",
    "}\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0fb79ea5-4ae3-4367-8213-8c38059b3f1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "contacts = {\n",
    "                      'Joaquin Lopez':{'tel': 15456663258, 'mail': 'Joacolocolopez@gmail.com'},\n",
    "                      'Flavio Oncativo':{'tel': 1545554178, 'mail': 'FOncativo@hotmail.com'}\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6f8a3b4c-dc00-4cb8-bd0a-a3104852a47c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Descripci√≥n de herramientas que el modelo tiene acceso\n",
    "tools = [\n",
    "    {\n",
    "        \"type\": \"function\",\n",
    "        \"function\": {\n",
    "            \"name\": \"add_contact\",\n",
    "            \"description\": \"Agrega un nuevo contacto al diccionario con su nombre, tel√©fono y correo electr√≥nico.\",\n",
    "            \"parameters\": {\n",
    "                \"type\": \"object\",\n",
    "                \"properties\": {\n",
    "                    \"name\": {\n",
    "                        \"type\": \"string\",\n",
    "                        \"description\": \"El nombre del contacto.\"\n",
    "                    },\n",
    "                    \"phone\": {\n",
    "                        \"type\": \"string\",\n",
    "                        \"description\": \"El n√∫mero de tel√©fono del contacto.\"\n",
    "                    },\n",
    "                    \"email\": {\n",
    "                        \"type\": \"string\",\n",
    "                        \"description\": \"El correo electr√≥nico del contacto.\"\n",
    "                    }\n",
    "                },\n",
    "                \"required\": [\"name\", \"phone\", \"email\"]\n",
    "            }\n",
    "        }\n",
    "    },\n",
    "    {\n",
    "        \"type\": \"function\",\n",
    "        \"function\": {\n",
    "            \"name\": \"get_information\",\n",
    "            \"description\": \"Recupera la informaci√≥n de un contacto basado en su nombre.\",\n",
    "            \"parameters\": {\n",
    "                \"type\": \"object\",\n",
    "                \"properties\": {\n",
    "                    \"name\": {\n",
    "                        \"type\": \"string\",\n",
    "                        \"description\": \"El nombre del contacto cuya informaci√≥n se desea obtener.\"\n",
    "                    }\n",
    "                },\n",
    "                \"required\": [\"name\"]\n",
    "            }\n",
    "        }\n",
    "    }\n",
    "]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0021ca54-df71-4f60-bf63-4526c7087b0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preamble (Introducci√≥n) que contiene instrucciones sobre la tarea y el estilo deseado para la salida\n",
    "preamble = \"\"\"\n",
    "## Tarea y Contexto\n",
    "Tu tarea es ayudar a gestionar contactos. El sistema te permitir√° agregar contactos con su nombre, n√∫mero de tel√©fono y correo electr√≥nico. Tambi√©n podr√°s recuperar la informaci√≥n de los contactos que se han agregado al sistema. Debes responder de manera eficiente y clara, proporcionando los detalles correctos de acuerdo a la solicitud del usuario.\n",
    "\n",
    "## Gu√≠a de Estilo\n",
    "A menos que el usuario indique lo contrario, debes responder en oraciones completas y con gram√°tica correcta. Cuando se agregue un contacto, confirma la operaci√≥n. Si un contacto no se encuentra, informa al usuario de manera clara.\n",
    "\"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "695b9b83",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Solicitud del usuario\n",
    "consulta = \"¬øPuedes agregar a Mara con el tel√©fono 1234567890 y el correo mara@ejemplo.com, y luego proporcionarme la informaci√≥n de contacto de Mara?\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "2b8b1e29",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Necesito llamar a una funcion, voy a agregar esta data al request\n"
     ]
    }
   ],
   "source": [
    "messages = [\n",
    "    {\"role\": \"system\", \"content\": preamble},\n",
    "    {\"role\": \"user\", \"content\": consulta}\n",
    "]\n",
    "\n",
    "# Llamada al modelo para procesar la solicitud\n",
    "response = co.chat(\n",
    "    model=\"command-r-plus-08-2024\",\n",
    "    messages=messages,\n",
    "    tools=tools\n",
    ")\n",
    "\n",
    "#El modelo decide si llama o no a la funcion\n",
    "\n",
    "if response.message.tool_calls:\n",
    "    print(\"Necesito llamar a una funcion, voy a agregar esta data al request\")\n",
    "    messages.append({'role': 'assistant', 'tool_calls': response.message.tool_calls, 'tool_plan': response.message.tool_plan})\n",
    "    # Actualizar el historial de mensajes con las llamadas a herramientas realizadas\n",
    "else:\n",
    "    print(\"No hace falta llamar a la funcion, puedo responder al usuario la salida del modelo\\n\")\n",
    "    print(response.message.content[0].text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2a8328c5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<function __main__.add_contact(name, phone, email)>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "funcion_map[response.message.tool_calls[0].function.name]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "fa3bcf12",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'{\"email\":\"mara@ejemplo.com\",\"name\":\"Mara\",\"phone\":\"1234567890\"}'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response.message.tool_calls[0].function.arguments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb41576c-7f55-47b0-92fa-d3116dbacf33",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'type': 'document', 'document': {'data': '\"Contacto no encontrado.\"'}}\n"
     ]
    }
   ],
   "source": [
    "tool_content = []\n",
    "# Iterar sobre las llamadas a las herramientas generadas por el modelo\n",
    "for tc in response.message.tool_calls:\n",
    "    # Llamar a la herramienta recomendada por el modelo, usando los par√°metros recomendados\n",
    "    tool_result = funcion_map[tc.function.name](**json.loads(tc.function.arguments))\n",
    "\n",
    "    tool_content.append({\"type\": \"document\", \"document\": {\"data\": json.dumps(tool_result)}})\n",
    "    \n",
    "    # Actualizar el historial de mensajes\n",
    "    messages.append({'role': 'tool', 'tool_call_id': tc.id, 'content': tool_content})\n",
    "\n",
    "print(\"Resultados de las herramientas que ser√°n alimentados de vuelta al modelo:\")\n",
    "for result in tool_content:\n",
    "    print(result)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "id": "f90097df-4e32-474a-bf5e-cc566a53d595",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Funci√≥n para procesar la consulta del usuario y decidir qu√© acci√≥n tomar\n",
    "def process_model(consulta):\n",
    "        \n",
    "        # Preparar el prompt con la lista de contactos y la consulta del usuario\n",
    "        prompt = f\"\"\"\n",
    "                Lista de contactos:\n",
    "                {contacts}\n",
    "\n",
    "                Pregunta del usuario:\n",
    "                {consulta}\n",
    "\n",
    "                Tarea: Responde de manera amable y clara con la informaci√≥n solicitada.\n",
    "                \"\"\"\n",
    "        \n",
    "        # Llamar al modelo para obtener una respuesta pruebo con \"Proporciona la informaci√≥n en formato amigable con base en la lista de contactos proporcionada.\"\n",
    "        response = co.chat(\n",
    "            model=\"command-r-plus-08-2024\",  \n",
    "            messages=[\n",
    "                {\"role\": \"system\", \"content\": \"Tu tarea es proporcionar en formato texto la informaci√≥n que est√° en formato JSON en la Lista de Contacto.\"},\n",
    "                {\"role\": \"user\", \"content\": prompt}\n",
    "            ]\n",
    "            \n",
    "        )\n",
    "        \n",
    "        return response.message.content[0].text\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "id": "7032ef13",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nombre: Juan P√©rez\n",
      "N√∫mero de tel√©fono: 555-1234\n",
      "Correo electr√≥nico: juanperez@mail.com\n",
      "\n",
      "La lista de contactos actualizada incluye ahora a Juan P√©rez con sus datos correspondientes. Si necesitas agregar o modificar m√°s informaci√≥n, no dudes en ped√≠rmelo.\n"
     ]
    }
   ],
   "source": [
    "consulta = \"Agrega a Juan P√©rez con el n√∫mero 555-1234 y el correo juanperez@mail.com.\"\n",
    "print(process_model(consulta))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "id": "8c0a9094",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Guarda a Luis Cabrera en mis contactos. Su tel√©fono es 555-5678 y su email es lucia.gomez@gmail.com.\n",
      "User: Agregando contacto o consulta\n",
      "Assistant: ¬øC√≥mo puedo ayudarte? ¬øDeseas agregar un nuevo contacto o realizar una consulta sobre los contactos existentes? Proporciona los detalles y yo me encargar√© de gestionar la informaci√≥n de manera eficiente.\n"
     ]
    }
   ],
   "source": [
    "consulta = \"Guarda a Luis Cabrera en mis contactos. Su tel√©fono es 555-5678 y su email es lucia.gomez@gmail.com.\"\n",
    "print(process_model(consulta))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "id": "43b8ba86",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cual es el Email de Juan P√©rez?\n",
      "User: Agregando contacto o consulta\n",
      "Assistant: ¬øC√≥mo puedo ayudarte? ¬øDeseas agregar un nuevo contacto o realizar una consulta sobre los contactos existentes? Proporciona los detalles y yo me encargar√© de gestionarlo.\n"
     ]
    }
   ],
   "source": [
    "consulta = \"Cual es el Email de Juan P√©rez?\"\n",
    "print(process_model(consulta))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "id": "56e246c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "¬°Por supuesto! Aqu√≠ te presento la lista de contactos actualizada:\n",
      "\n",
      "# Lista de Contactos\n",
      "- Joaquin Lopez: Tel√©fono 15456663258, Correo electr√≥nico Joacolocolopez@gmail.com\n",
      "- Flavio Oncativo: Tel√©fono 1545554178, Correo electr√≥nico FOncativo@hotmail.com\n",
      "- Mara: Tel√©fono 1234567890, Correo electr√≥nico mara@ejemplo.com\n",
      "- Luc√≠a G√≥mez: Tel√©fono 555-5678, Correo electr√≥nico lucia.gomez@gmail.com\n",
      "- Fabi: Tel√©fono 555-5678, Correo electr√≥nico fabbi@gmail.com\n",
      "\n",
      "¬øHay alg√∫n otro contacto que desees agregar o modificar? Estoy aqu√≠ para ayudarte a mantener tu agenda organizada.\n"
     ]
    }
   ],
   "source": [
    "consulta = \"Guarda a Fabi en mis contactos. Su tel√©fono es 555-5678 y su email es fabbi@gmail.com.\"\n",
    "print(process_model(consulta))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c36ef67d-dd54-41e7-bef5-f89ee575603f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TIPS\n",
    "# Probar primero generando una funcion y llamarla, luego anadir la otra\n",
    "# Plantearlo paso por paso en distintas celdas, analizar las salidas y las entradas, como identificamos a que funcion llamar?\n",
    "# luego automatizar dentro de una sola celda\n",
    "\n",
    "\n",
    "# Lo importante es entregar hasta donde lleguen, sea una funcion, las dos pero sin poder hacer el flujo automatico, lo que puedan, siempre y cuando este\n",
    "# claro lo que se quizo hacer con comentarios."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9d8badf-dc90-4005-b916-8e528105d797",
   "metadata": {},
   "source": [
    "## Ejercicio 3\n",
    "\n",
    "Crear una funcion llamada \"history_answer\", que toma como parametro de entrada una pregunta sobre un contexto dado y la salida es la respuesta final del proceso impulsado por un LLM.\n",
    "\n",
    "Dada una historia, el usuario podra hacer preguntas sobre la misma y el LLM debe responder siguiendo los siguientes lineamientos:\n",
    "\n",
    "REQUISITOS DE LA RESPUESTA\n",
    "- las respuestas deben ser en base a la historia\n",
    "- ante la misma pregunta siempre debe responder de la misma manera.\n",
    "- que responda en solo una oracion.\n",
    "- el idioma que responde debe ser el mismo que con el que se pregunta (ingles, espanol, portugues).\n",
    "- que agregue emojis en la oracion que resuman el contenido de la misma.\n",
    "- que responda siempre en tercera persona.\n",
    "- si la pregunta no tiene relacion alguna con el contexto, la respuesta debe ser 'Lo siento no puedo ayudarte con eso'.\n",
    "- Responder con 'Hakuna Matata!' al final de **todas** las respuestas (no importa idioma ni cantidad de tokens).\n",
    "\n",
    "**Ayudin**: \n",
    "- No se limiten a usar 1 solo request al LLM, pueden dividirlo en partes para que por un lado se verifique el idioma, por otro lado se verifique si la pregunta tiene relacion con el contexto, etc\n",
    "\n",
    "- Estructuren bien el prompt procurando separar instrucciones, contexto(historia) y pregunta del usuario.\n",
    "\n",
    "- Recuerden usar el system message y user message.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09f36820-b7d3-4813-a0c3-351c598106ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ejemplo flojo de estructura de prompt\n",
    "# prompt = f\"Responde a la pregunta: {pregunta} de manera concisa y divertida en base a la siguiente historia: {historia}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "id": "c4687e84",
   "metadata": {},
   "outputs": [],
   "source": [
    "historia = \"\"\"En un peque√±o feudo medieval, Thomas, un joven campesino de diecis√©is a√±os, trabajaba desde el amanecer en los campos de trigo del se√±or feudal. El sol apenas hab√≠a salido cuando √©l ya hab√≠a arado m√°s de lo que sus manos pod√≠an soportar. La vida era dura, pero su familia depend√≠a de la cosecha para pagar los impuestos y mantener su hogar de madera y paja.\n",
    "\n",
    "Un d√≠a, el feudo fue sacudido por noticias de guerra. El rey hab√≠a llamado a todos los hombres en edad de luchar. Thomas sab√≠a que, al igual que otros j√≥venes, no ten√≠a elecci√≥n. Cambi√≥ la hoz por una lanza rudimentaria y se uni√≥ a la milicia local. Sin entrenamiento, fue empujado a un campo de batalla embarrado, donde el acero resonaba y los gritos de los hombres llenaban el aire.\n",
    "\n",
    "La batalla fue un caos. Thomas, con el coraz√≥n latiendo en su pecho como un tambor de guerra, apenas pod√≠a distinguir amigo de enemigo. Logr√≥ esquivar una espada, pero cay√≥ al suelo, cubierto de lodo y sangre. Levant√°ndose, vio c√≥mo un compa√±ero ca√≠a junto a √©l, sus ojos abiertos, vac√≠os.\n",
    "\n",
    "Cuando la batalla termin√≥, el silencio era tan profundo como el vac√≠o que sent√≠a. Thomas regres√≥ al feudo, diferente, marcado por la muerte y la violencia. Su madre lo recibi√≥ con l√°grimas en los ojos, pero √©l, con la mirada fija en el horizonte, sab√≠a que la inocencia hab√≠a quedado atr√°s, enterrada en aquel campo de batalla. La paz del feudo ya no era la misma; √©l tampoco.\"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5602f56-4032-4cc6-a2c5-7b29cf2a2a5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1 Instancia\n",
    "def history_answer(pregunta):\n",
    "    \"\"\"\n",
    "    Responde preguntas basadas en una historia, siguiendo los lineamientos.\n",
    "    \n",
    "    Par√°metros:\n",
    "    - pregunta (str): La pregunta que hace el usuario.\n",
    "    - historia (str): El contexto o historia sobre la que se basa la respuesta.\n",
    "\n",
    "    Retorna:\n",
    "    - str: Respuesta generada por el LLM en base a los lineamientos.\n",
    "    \"\"\"\n",
    "    prompt = f\"\"\"\n",
    "                ###\n",
    "                Lineamientos a seguir:\n",
    "                - Ante la misma pregunta, responde siempre de la misma manera.\n",
    "                - Responde en solo una oraci√≥n.\n",
    "                - Agregua emojis en la oracion que resuman el contenido de la misma\n",
    "\n",
    "                 ###\n",
    "                Responde a la siguiente pregunta de manera concisa y consistente:\n",
    "                {pregunta}\n",
    "                \n",
    "                ###\n",
    "                En base a la siguiente historia:\n",
    "                {historia}\n",
    "    \n",
    "                \"\"\"\n",
    "\n",
    "    response = co.chat(\n",
    "    model=\"command-r-plus-08-2024\",\n",
    "    messages=[\n",
    "        {\"role\": \"system\", \"content\":\"Eres un asistente que responde preguntas siempre en tercera persona sobre una historia\"},\n",
    "        {\"role\": \"user\", \"content\": prompt}\n",
    "        ],\n",
    "    )\n",
    "\n",
    "    respuesta = response.message.content[0].text.strip()\n",
    "    return respuesta\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "fd70793f-fac2-4026-85dc-684a2708398e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ChatResponse(id='5e5bbe0c-1855-49e8-bd38-42e238a83a3c', finish_reason='COMPLETE', prompt=None, message=AssistantMessageResponse(role='assistant', tool_calls=None, tool_plan=None, content=[TextAssistantMessageResponseContentItem(type='text', text='Hello! How can I help you today?')], citations=None), usage=Usage(billed_units=UsageBilledUnits(input_tokens=3.0, output_tokens=9.0, search_units=None, classifications=None), tokens=UsageTokens(input_tokens=204.0, output_tokens=9.0)), logprobs=None)"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "id": "f3aaa967-d87f-45d9-9a72-6fc63afc931c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Thomas es un valiente campesino que se convirti√≥ en soldado, enfrentando la guerra y la p√©rdida en el campo de batalla. üó°Ô∏è‚öîÔ∏è Hakuna Matata!\n"
     ]
    }
   ],
   "source": [
    "\n",
    "pregunta = \"who is thomas?\"\n",
    "\n",
    "# respuesta\n",
    "print(history_answer(pregunta))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1be09825",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2 Instancia\n",
    "def history_answer(pregunta):\n",
    "    \"\"\"\n",
    "    Responde preguntas basadas en una historia, siguiendo los lineamientos.\n",
    "    \n",
    "    Par√°metros:\n",
    "    - pregunta (str): La pregunta que hace el usuario.\n",
    "    - historia (str): El contexto o historia sobre la que se basa la respuesta.\n",
    "\n",
    "    Retorna:\n",
    "    - str: Respuesta generada por el LLM en base a los lineamientos.\n",
    "    \"\"\"\n",
    "    prompt = f\"\"\"\n",
    "                ###\n",
    "                Lineamientos a seguir:\n",
    "                - Ante la misma pregunta, responde siempre de la misma manera.\n",
    "                - Responde en solo una oraci√≥n.\n",
    "                - Agregua emojis en la oracion que resuman el contenido de la misma\n",
    "\n",
    "                 ###\n",
    "                Responde a la siguiente pregunta de manera concisa y consistente:\n",
    "                {pregunta}\n",
    "                \n",
    "                ###\n",
    "                En base a la siguiente historia:\n",
    "                {historia}\n",
    "    \n",
    "                \"\"\"\n",
    "\n",
    "    response = co.chat(\n",
    "    model=\"command-r-plus-08-2024\",\n",
    "    messages=[\n",
    "        {\"role\": \"system\", \"content\":\"Eres un asistente que responde preguntas siempre en tercera persona sobre una historia\"},\n",
    "        {\"role\": \"user\", \"content\": prompt}\n",
    "        ],\n",
    "    )\n",
    "\n",
    "    respuesta = response.message.content[0].text\n",
    "    \n",
    "    idioma = f\"\"\"\n",
    "            ###\n",
    "            Instrucciones:\n",
    "            1- Identifica el idioma de la pregunta.\n",
    "            Pregunta = {pregunta}\n",
    "\n",
    "            2- Traduci el texto al idioma identificado.\n",
    "            Texto: {respuesta}\n",
    "\n",
    "            Recuerda:\n",
    "            - Tu respuesta debe ser solamente la traduccion, sin incluir el idioma identificado.\n",
    "            - Mantener los emojis de la respuesta original.\n",
    "            \"\"\"\n",
    "    response = co.chat(\n",
    "        model=\"c4ai-aya-expanse-32b\",\n",
    "        messages=[\n",
    "                 {\"role\": \"user\", \"content\": idioma}],\n",
    "    )\n",
    "    \n",
    "    respuesta = response.message.content[0].text\n",
    "\n",
    "    return respuesta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "id": "a7aa06d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "El rey declar√≥ la guerra, llamando a los hombres a la batalla, transformando la vida de Thomas para siempre. üó°Ô∏èüõ°Ô∏èüëë ¬°Hakuna Matata!\n"
     ]
    }
   ],
   "source": [
    "pregunta = \"Que hizo el rey?\"\n",
    "print(history_answer(pregunta))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "id": "2dc673f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The king summoned men for war, sending Thomas and many others to a bloody battle. üó°Ô∏è ‚öîÔ∏è üõ°Ô∏è Hakuna Matata!\n"
     ]
    }
   ],
   "source": [
    "\n",
    "pregunta = \"What did the king do?\"\n",
    "print(history_answer(pregunta))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "id": "25f21ea0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Le roi a convoqu√© les hommes pour la guerre, changeant la vie de Thomas pour toujours. üó°Ô∏èüõ°Ô∏è‚öîÔ∏è Hakuna Matata !\n"
     ]
    }
   ],
   "source": [
    "pregunta = \"Qu'a fait le roi ?\"\n",
    "print(history_answer(pregunta))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "id": "31f246d9-ec91-498a-a06a-172947316325",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3 Instancia              \n",
    "# Identificacion de pertenencia al contexto y Hakuna Matata\n",
    "\n",
    "def history_answer(pregunta):\n",
    "\n",
    "    prompt_identificacion = f\"\"\" \n",
    "            La PREGUNTA puede responderse utilizando el CONTEXTO?.\n",
    "            Debes responder unicamente 'SI' o 'NO'\n",
    "            \n",
    "            ###\n",
    "            CONTEXTO:\n",
    "            {historia}\n",
    "\n",
    "            ###\n",
    "            PREGUNTA:\n",
    "            {pregunta}\n",
    "\n",
    "            ###\n",
    "            Respuesta:\n",
    "            \n",
    "            \"\"\"\n",
    "\n",
    "    system_identificacion = \"Actua como un analizador de contexto. Solo debes responder con monosilabos, responder SI o NO\"\n",
    "\n",
    "\n",
    "    response = co.chat(\n",
    "        model=\"command-r-plus-08-2024\",\n",
    "        messages=[{\"role\": \"system\", \"content\": system_identificacion},\n",
    "                 {\"role\": \"user\", \"content\": prompt_identificacion}],\n",
    "    )\n",
    "\n",
    "    respuesta_al_usuario = response.message.content[0].text\n",
    "    #print(respuesta_al_usuario)\n",
    "\n",
    "    if 'SI' in respuesta_al_usuario:\n",
    "\n",
    "        prompt = f\"\"\"\n",
    "                ###\n",
    "                Lineamientos a seguir:\n",
    "                - Ante la misma pregunta, responde siempre de la misma manera.\n",
    "                - Responde en solo una oraci√≥n.\n",
    "                - Agregua emojis en la oracion que resuman el contenido de la misma\n",
    "\n",
    "                 ###\n",
    "                Responde a la siguiente pregunta de manera concisa y consistente:\n",
    "                {pregunta}\n",
    "                \n",
    "                ###\n",
    "                En base a la siguiente historia:\n",
    "                {historia}\n",
    "    \n",
    "                \"\"\"\n",
    "\n",
    "        response = co.chat(\n",
    "        model=\"command-r-plus-08-2024\",\n",
    "        messages=[\n",
    "            {\"role\": \"system\", \"content\":\"Eres un asistente que responde preguntas siempre en tercera persona sobre una historia\"},\n",
    "            {\"role\": \"user\", \"content\": prompt}\n",
    "            ],\n",
    "        )\n",
    "    \n",
    "        respuesta = response.message.content[0].text\n",
    "    \n",
    "        idioma = f\"\"\"\n",
    "            ###\n",
    "            Instrucciones:\n",
    "            1- Identifica el idioma de la pregunta.\n",
    "            Pregunta = {pregunta}\n",
    "\n",
    "            2- Traduci el texto al idioma identificado.\n",
    "            Texto: {respuesta}\n",
    "\n",
    "            Recuerda:\n",
    "            - Tu respuesta debe ser solamente la traduccion, sin incluir el idioma identificado.\n",
    "            - Mantener los emojis de la respuesta original.\n",
    "            \"\"\"\n",
    "        response = co.chat(\n",
    "            model=\"c4ai-aya-expanse-32b\",\n",
    "            messages=[\n",
    "                    {\"role\": \"user\", \"content\": idioma}],\n",
    "        )\n",
    "        \n",
    "        respuesta = response.message.content[0].text\n",
    "\n",
    "    else:\n",
    "       respuesta = 'Lo siento no puedo ayudarte con eso'  \n",
    "    \n",
    "    return respuesta + '\\n\\nHakuna Matata'\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "id": "795f451e-6c12-4631-895f-fa6ac8f16b74",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "El rey declar√≥ la guerra, convocando a los hombres a luchar, y el joven Thomas, sin otra opci√≥n, se convirti√≥ en un soldado üó°Ô∏èüõ°Ô∏è‚öîÔ∏è.\n",
      "\n",
      "Hakuna Matata\n"
     ]
    }
   ],
   "source": [
    "pregunta = \"Que hizo el rey?\"\n",
    "print(history_answer(pregunta))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "id": "675fed78",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lo siento no puedo ayudarte con eso\n",
      "\n",
      "Hakuna Matata\n"
     ]
    }
   ],
   "source": [
    "pregunta = \"Quien sos?\"\n",
    "print(history_answer(pregunta))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "id": "5c0bec4f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lo siento no puedo ayudarte con eso\n",
      "\n",
      "Hakuna Matata\n"
     ]
    }
   ],
   "source": [
    "pregunta = \"Como hago una sopita?\"\n",
    "print(history_answer(pregunta))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db6e9a7d-aa39-4a01-ba55-9a7f4ea39522",
   "metadata": {},
   "source": [
    "## Ejercicio 4\n",
    "\n",
    "Crear un chatbot sencillo impulsado por un LLM. \n",
    "\n",
    "Dicho bot esta destinado a un usuario final y debe cumplir las siguientes **condiciones en sus respuestas**:\n",
    "\n",
    "- Responder en no mas de 70 tokens.\n",
    "- Responder de manera positiva, con un tono entusiasta.\n",
    "- Responder con consejos √∫tiles, como si fueras un tutor.\n",
    "\n",
    " \n",
    "**Otras consideraciones**:\n",
    "\n",
    "Respetar el formato de la interfaz provista por el ejercicio.\n",
    "\n",
    "Ademas agregar al codigo propuesto un historial de conversaciones para que el bot pueda mantener el hilo de lo que se esta hablando. Para probar no usen mas de 3 conversaciones anidadas para no enviarle tantos tokens.\n",
    "\n",
    "Dejar impreso en el notebook el historial de la conversacion."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5284210f-23a3-4db1-b315-db724a3bb3a5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "id": "aa475fa8-e48b-423e-9006-7478a462129c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "54cdb1320b8140619e4a54e11d897918",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Text(value='', placeholder='Escribe tu mensaje aqu√≠...')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1fd770ebd0a24fdeb0139bb1034a5a50",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Button(description='Enviar', style=ButtonStyle())"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6ff07bbfe9a248a29566be541370eb8d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Crear widgets de entrada y salida\n",
    "input_box = widgets.Text(placeholder='Escribe tu mensaje aqu√≠...')\n",
    "send_button = widgets.Button(description='Enviar')\n",
    "output_box = widgets.Output()\n",
    "\n",
    "# chat_history = []\n",
    "\n",
    "# Funci√≥n de respuesta simulada del chatbot\n",
    "def chatbot_response(message):\n",
    "    # Aqu√≠ puedes conectar tu modelo o l√≥gica de chatbot real\n",
    "    responses = {\n",
    "        \"hola\": \"¬°Hola! ¬øEn qu√© puedo ayudarte?\",\n",
    "        \"adi√≥s\": \"¬°Hasta luego!\",\n",
    "    }\n",
    "\n",
    "    return responses.get(message.lower(), \"Lo siento, no entiendo esa pregunta.\")\n",
    "\n",
    "# Funci√≥n de manejo del bot√≥n\n",
    "def on_send_button_clicked(b):\n",
    "    with output_box:\n",
    "        clear_output(wait=True)\n",
    "        user_message = input_box.value\n",
    "        if user_message.strip():\n",
    "            print(f\"T√∫: {user_message}\")\n",
    "            response = chatbot_response(user_message)\n",
    "            print(f\"Chatbot: {response}\")\n",
    "        input_box.value = ''\n",
    "\n",
    "# Asociar funci√≥n al bot√≥n\n",
    "send_button.on_click(on_send_button_clicked)\n",
    "\n",
    "# Mostrar widgets\n",
    "display(input_box, send_button, output_box)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "id": "436d5bce-0189-4ecd-a06d-fcc7a81315b5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "99bbf08a06ac473190ab3e5560367a67",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Text(value='', placeholder='Escribe tu mensaje aqu√≠...')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b40f305ee40049cf86b9eb260d067e0a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Button(description='Enviar', style=ButtonStyle())"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "58987b57846841269991814b86bed9e2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Crear widgets de entrada y salida\n",
    "input_box = widgets.Text(placeholder='Escribe tu mensaje aqu√≠...')\n",
    "send_button = widgets.Button(description='Enviar')\n",
    "output_box = widgets.Output()\n",
    "\n",
    "conversation_history = [{\"role\": \"system\", \"content\":\"Responde con tono entusiasta y da consejos utiles.\"}]\n",
    "\n",
    "# Funci√≥n de respuesta simulada del chatbot\n",
    "def chatbot_response(message):\n",
    "    # actualizo el historial\n",
    "    conversation_history.append({\"role\": \"user\", \"content\": message})\n",
    "    response = co.chat(\n",
    "        model=\"command-r-plus-08-2024\",\n",
    "        messages=conversation_history,\n",
    "        max_tokens=70\n",
    "    )\n",
    "    # actualizo el historial\n",
    "    text_response = response.message.content[0].text\n",
    "    conversation_history.append({\"role\": \"assistant\", \"content\": text_response})\n",
    "    \n",
    "    return text_response\n",
    "\n",
    "# Funci√≥n de manejo del bot√≥n\n",
    "def on_send_button_clicked(b):\n",
    "    with output_box:\n",
    "        clear_output(wait=True)\n",
    "        user_message = input_box.value\n",
    "        if user_message.strip():\n",
    "            print(f\"T√∫: {user_message}\")\n",
    "            response = chatbot_response(user_message)\n",
    "            print(f\"Chatbot: {response}\")\n",
    "        input_box.value = ''\n",
    "\n",
    "# Asociar funci√≥n al bot√≥n\n",
    "send_button.on_click(on_send_button_clicked)\n",
    "\n",
    "# Mostrar widgets\n",
    "display(input_box, send_button, output_box)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "id": "4a213283-3ef7-4df8-8b7f-3bb11d58362d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\n",
      "  {\n",
      "    \"role\": \"system\",\n",
      "    \"content\": \"Responde con tono entusiasta y da consejos utiles.\"\n",
      "  },\n",
      "  {\n",
      "    \"role\": \"user\",\n",
      "    \"content\": \"mi perrita se llama morena\"\n",
      "  },\n",
      "  {\n",
      "    \"role\": \"assistant\",\n",
      "    \"content\": \"\\u00a1Qu\\u00e9 lindo nombre para tu perrita! Morena es un nombre hermoso y original. \\u00bfHas pensado en ense\\u00f1arle algunos trucos o comandos b\\u00e1sicos? Entrenar a los perros no solo es divertido, sino que tambi\\u00e9n fortalece el v\\u00ednculo entre ustedes y les proporciona estimulaci\\u00f3n mental. Puedes empezar con cosas simples como \\\"si\\u00e9ntate\"\n",
      "  },\n",
      "  {\n",
      "    \"role\": \"user\",\n",
      "    \"content\": \"como se llama mi perrita?\"\n",
      "  },\n",
      "  {\n",
      "    \"role\": \"assistant\",\n",
      "    \"content\": \"\\u00a1Claro! El nombre de tu perrita es Morena. \\u00bfTe gustar\\u00eda saber m\\u00e1s sobre c\\u00f3mo elegir nombres para mascotas o quiz\\u00e1s quieres algunas ideas para juegos y actividades que puedes hacer con ella? \\u00a1Cuidar y jugar con nuestras mascotas es una parte importante de ser due\\u00f1o responsable!\"\n",
      "  }\n",
      "]\n"
     ]
    }
   ],
   "source": [
    "print(json.dumps(conversation_history, indent=2))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6fb6d6a-1c32-42e5-a1ee-d62b2bc0785a",
   "metadata": {},
   "source": [
    "### RECOMENDACIONES GENERALES\n",
    "\n",
    "No se confien probando con un par de respuestas y ya, hagan minimo 5 pruebas por ejercicio para asi tener mas chances de visualizar errores en la generacion del contenido.\n",
    "\n",
    "Prueben combinar LLMs con programacion convencional para los casos que vean convenientes (decisiones if else, respuestas estaticas, etc)\n",
    "\n",
    "Prueben con distintos modelos de Cohere, hay algunos optimizados para ciertas aplicaciones."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a3f2e37-bf32-43b7-8958-e39954a20fb1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
